(import ast.parser)

(mut fileContent "")
(mut index 0)
(mut current "")

(let keywords [
  "if" "return" "switch" "for" "while"
  "class" "public" "private" "static"
  "import" "enum" "extends" "implements"
  "null" "false" "true" "else" "break"
])

(let ope [
  ";" "{" "}" "[" "]" "(" ")"
  "=" "-" "*" "/" "\"" "'"
])

(let numbers [
  0 1 2 3 4 5 6 7 8 9
])

(let alpha [
  "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
  "n" "o" "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z"
  "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M"
  "N" "O" "P" "Q" "R" "S" "T" "U" "V" "W" "X" "Y" "Z"
])

(let isNumber (fun (_string) {
  (mut _output false)
  (mut _index 0)

  (while (< _index (len numbers)) {
    (if (= (@ numbers _index) (toNumber _string)) {
      (set _output true)
    })
    (set _index (+ 1 _index))
  })

  _output  
}))

(let isAlpha (fun (_string) {
  (mut _output false)
  (mut _index 0)
  
  (while (< _index (len alpha)) {
    (if (= (@ alpha _index) _string) {
      (set _output true)
    })
    (set _index (+ 1 _index))
  })
  
  _output
}))

(let next (fun () {
  (mut _output "")
  
  (if (< (+ 1 index) (len fileContent)) {
    (set index (+ 1 index))
    (set current (@ fileContent (- index 1)))
    (set _output (@ fileContent index))
  }(set current ""))
  
  _output
}))

(let isKeyword (fun (_string) {
  (mut _output false)
  
  (if (= (type _string) "String") {
    (mut _index 0)
    (while (< _index (len keywords)) {
      (if (= (@ keywords _index) _string) {
        (set _output true)})
      (set _index (+ 1 _index))
    })
  })
  
  _output
}))

(let getTokens(fun () {
  (mut buffer "")
  (mut tokens [])

  (while (= (isAlpha current) true) {
    (set buffer (+ buffer current))
    (next)
  })

  (if (= (isKeyword buffer) true) {
    (set tokens (append tokens (newToken "Keyword" buffer)))
  }{
    (if (!= buffer ""){
      (set tokens (append tokens (newToken "Identifier" buffer)))
    })
  })  

  (mut _index 0)
  (while (< _index (len ope)) {
    (if (= (@ ope _index) current) {
      (set tokens (append tokens (newToken "Operator" current)))
    })
    (set _index (+ 1 _index))
  })
  
  tokens
}))

(let tokenize (fun (file_path) {
  (assert (= (type file_path) "String") "file_path needs to be a String.")
  (assert (io:fileExists? file_path) "file not found.")

  (set fileContent (io:readFile file_path))
  (mut tokens [])
  (mut i 0)
  (mut buffer "")

  (while (!= i (len fileContent)) {
    (mut tok (getTokens))
    
    (if (!= (len tok) 0) {
      (set tokens (append tokens tok))
    })
    
    (next)
    (set i (+ 1 i))
  })

  tokens 
}))